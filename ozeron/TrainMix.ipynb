{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# %load utils.py\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def dump_model(path, model):\n",
    "    with open(path, 'wb') as f:\n",
    "        pickle.dump(model, f)\n",
    "\n",
    "def load_dumped(path):\n",
    "    result = None\n",
    "    with open(path, 'rb') as f:\n",
    "        result = pickle.load(f)\n",
    "    return result\n",
    "\n",
    "def load_and_split(name):\n",
    "    path = \"../data/%s.csv\" % name\n",
    "    df = pd.read_csv(path, sep=\"|\")\n",
    "    return train_test_split(df[['text']], df['label'], test_size=0.2, random_state=42, stratify=df['label'])\n",
    "\n",
    "def load_and_split_quick(name):\n",
    "    path = \"../data/%s.csv\" % name\n",
    "    df = pd.read_csv(path, sep=\"|\")\n",
    "    processed = load_dumped(\"../data/processed/%s.bin\" % name)\n",
    "    return train_test_split(df[['text']], df['label'], test_size=0.2, random_state=42, stratify=df['label'])\n",
    "\n",
    "\n",
    "def other_name(name):\n",
    "    other_dataset = 'imdb_small'\n",
    "    if (name == 'imdb_small'):\n",
    "        other_dataset = 'reviews_rt_all'\n",
    "    return other_dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# %load train.py\n",
    "\n",
    "import pandas as pd\n",
    "import re\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "from sklearn.externals import joblib\n",
    "\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "\n",
    "from pipeline.text_cleaner import TextCleaner\n",
    "from pipeline.stemmer import Stemmer\n",
    "from pipeline.dataframe_vectorizer import DataframeVectorizer\n",
    "from pipeline.lemmatizer import Lemmatizer\n",
    "\n",
    "from utils import dump_model, load_and_split, other_name, load_file\n",
    "\n",
    "import pickle\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn import metrics\n",
    "import pickle\n",
    "import datetime\n",
    "\n",
    "STOPWORDS = ['a','an','by','did','does', 'was', 'were', 'i', 'the', 'and', 'if']\n",
    "\n",
    "#global\n",
    "DataPipeline = Pipeline(steps=[\n",
    "        ('clean_words', TextCleaner(key='text')),\n",
    "        ('lemmatizer', Lemmatizer()),\n",
    "        ('stemmer', Stemmer()),\n",
    "        ('vectorize', DataframeVectorizer(vectorizer=CountVectorizer(ngram_range=(1, 2),stop_words=STOPWORDS))),\n",
    "        ])\n",
    "#global\n",
    "FastDataPipeline = Pipeline(steps=[('vectorize', DataframeVectorizer(vectorizer=CountVectorizer()))])\n",
    "\n",
    "#global\n",
    "LearningPipeline = Pipeline(steps=[\n",
    "    ('logistic', LogisticRegressionCV(n_jobs=2,verbose=1))\n",
    "])\n",
    "\n",
    "def dump_models(name, f1_score, time_mark,\n",
    "                data_pipeline=DataPipeline,\n",
    "                learn_pipeline=LearningPipeline):\n",
    "    path = '../dumps/history/%s__%s__%s__' % (name, time_mark, f1_score)\n",
    "    dump_model(path + 'data.bin', data_pipeline)\n",
    "    dump_model(path + 'learn.bin', learn_pipeline)\n",
    "    path = '../dumps/%s__' % (name)\n",
    "    dump_model(path + 'data.bin', data_pipeline)\n",
    "    dump_model(path + 'learn.bin', learn_pipeline)\n",
    "\n",
    "def store_results(name, y, predicted,\n",
    "                  data_pipeline=DataPipeline,\n",
    "                  learn_pipeline=LearningPipeline):\n",
    "    acc = round(metrics.accuracy_score(y, predicted), 5)\n",
    "\n",
    "    dt=datetime.datetime.now()\n",
    "    time_mark = dt.strftime('%Y%m%d%H%M')\n",
    "\n",
    "    dump_models(name, acc, time_mark,\n",
    "                data_pipeline=data_pipeline,\n",
    "                learn_pipeline=learn_pipeline)\n",
    "\n",
    "def calculate_other_performance(name):\n",
    "    other_dataset = other_name(name)\n",
    "    X_train, X_test, y_train, y_test = load_and_split(other_dataset)\n",
    "    calculate_performance(name, other_dataset, X_test, y_test)\n",
    "\n",
    "def calculate_performance(trained, testing, X, y,\n",
    "                         data_pipeline=DataPipeline,\n",
    "                         learn_pipeline=LearningPipeline):\n",
    "    X_processed = data_pipeline.transform(X)\n",
    "    predicted = learn_pipeline.predict(X_processed)\n",
    "    print('Performance %s on %s' % (trained, testing))\n",
    "    print(metrics.classification_report(y, predicted))\n",
    "    print('Accuracy: ', metrics.accuracy_score(y, predicted))\n",
    "    return predicted\n",
    "\n",
    "def train(name):\n",
    "    data_pipeline = DataPipeline\n",
    "    X_train, X_test, y_train, y_test = load_and_split(name)\n",
    "\n",
    "\n",
    "    X_after_processing = data_pipeline.fit_transform(X_train)\n",
    "    print(\"Data processed!\")\n",
    "\n",
    "    LearningPipeline.fit(X_after_processing, y_train)\n",
    "    print(\"Models trained!\")\n",
    "\n",
    "    predicted = calculate_performance(name, name, X_test, y_test,\n",
    "                                     data_pipeline=data_pipeline)\n",
    "    store_results(name, y_test, predicted,\n",
    "                  data_pipeline=data_pipeline)\n",
    "    calculate_other_performance(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train_rt, X_test_rt, y_train_rt, y_test_rt = load_and_split('reviews_rt_all')\n",
    "X_train_imdb, X_test_imdb, y_train_imdb, y_test_imdb = load_and_split('imdb_small')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train = pd.concat([X_train_rt, X_train_imdb])\n",
    "X_test = pd.concat([X_test_rt, X_test_imdb])\n",
    "y_train = pd.concat([y_train_rt, y_train_imdb])\n",
    "y_test = pd.concat([y_test_rt, y_test_imdb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_p = DataPipeline.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import PassiveAggressiveClassifier\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "l = PassiveAggressiveClassifier(warm_start=False, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "params={'C': [7,9,10,15,20], 'n_iter':[20,50,100],  'loss':['squared_hinge']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clf=GridSearchCV(estimator=l, param_grid=params, scoring='accuracy', n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=None, error_score='raise',\n",
       "       estimator=PassiveAggressiveClassifier(C=1.0, class_weight=None, fit_intercept=True,\n",
       "              loss='hinge', n_iter=5, n_jobs=1, random_state=42,\n",
       "              shuffle=True, verbose=0, warm_start=False),\n",
       "       fit_params={}, iid=True, n_jobs=-1,\n",
       "       param_grid={'C': [0.01, 0.1, 1, 10, 100], 'n_iter': [5, 20], 'loss': ['squared_hinge', 'hinge']},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
       "       scoring='accuracy', verbose=0)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(X_p, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 10, 'loss': 'squared_hinge', 'n_iter': 20}\n"
     ]
    }
   ],
   "source": [
    "print(clf.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_test_d = DataPipeline.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation:\n",
      "Accuracy:  0.819179608151\n"
     ]
    }
   ],
   "source": [
    "predict = clf.predict(X_test_d)\n",
    "print('Validation:')\n",
    "print('Accuracy: ', metrics.accuracy_score(y_test, predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_v_rt = DataPipeline.transform(X_test_rt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_RT:\n",
      "Accuracy:  0.795780138388\n"
     ]
    }
   ],
   "source": [
    "predict = l.predict(X_v_rt)\n",
    "print('test_RT:')\n",
    "print('Accuracy: ', metrics.accuracy_score(y_test_rt, predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_v = DataPipeline.transform(X_test_imdb)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_imdb:\n",
      "Accuracy:  0.8832\n"
     ]
    }
   ],
   "source": [
    "predict = clf.predict(X_v)\n",
    "print('test_imdb:')\n",
    "print('Accuracy: ', metrics.accuracy_score(y_test_imdb, predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dump_model('../dumps/mix_data.bin', DataPipeline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clf=PassiveAggressiveClassifier(warm_start=False, random_state=42, **clf.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PassiveAggressiveClassifier(C=10, class_weight=None, fit_intercept=True,\n",
       "              loss='squared_hinge', n_iter=20, n_jobs=1, random_state=42,\n",
       "              shuffle=True, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(X_p, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation:\n",
      "Accuracy:  0.819179608151\n"
     ]
    }
   ],
   "source": [
    "predict = clf.predict(X_test_d)\n",
    "print('Validation:')\n",
    "print('Accuracy: ', metrics.accuracy_score(y_test, predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#dump_model('../dumps/mix_learn.bin', clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../dumps/mix_data.pcl']"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(DataPipeline, '../dumps/mix_data.pcl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../dumps/mix_learn.pcl']"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump( clf, '../dumps/mix_learn.pcl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
